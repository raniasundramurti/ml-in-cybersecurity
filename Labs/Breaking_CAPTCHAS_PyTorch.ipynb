{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Breaking CAPTCHAS with PyTorch**"
      ],
      "metadata": {
        "id": "q_m5f7tVidZj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mQyXaZfQez2H"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lab_2_helpers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Extract dataset\n",
        "!tar -xf captcha-images.tar.xz\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kXfxk-Gr18d",
        "outputId": "552a785d-60ab-41c7-afeb-1c0393463c91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "captcha-images\t       lab_2_helpers.py  sample_data\n",
            "captcha-images.tar.xz  __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Core preprocessing functions\n",
        "def load_transform_image(image_path: str):\n",
        "    # 1) read\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "    # 2) grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 3) padding\n",
        "    gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "    return gray\n",
        "\n",
        "def extract_captcha_text(image_path: str) -> str:\n",
        "    base = os.path.basename(image_path)\n",
        "    text = os.path.splitext(base)[0]\n",
        "    return text\n",
        "\n",
        "def extract_chars(gray_image):\n",
        "    \"\"\" Find contours and extract characters inside each CAPTCHA. \"\"\"\n",
        "    # Threshold image and convert it to black-white\n",
        "    image_bw = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "    # Find contours (continuous blobs of pixels) the image\n",
        "    contours = cv2.findContours(image_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "\n",
        "    char_regions = []\n",
        "    # Loop through each contour\n",
        "    for contour in contours:\n",
        "        # Get the rectangle that contains the contour\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Compare the width and height of the bounding box,\n",
        "        # detect if there are letters conjoined into one chunk\n",
        "        if w / h > 1.25:\n",
        "            # Bounding box is too wide for a single character\n",
        "            # Split it in half into two letter regions\n",
        "            half_width = int(w / 2)\n",
        "            char_regions.append((x, y, half_width, h))\n",
        "            char_regions.append((x + half_width, y, half_width, h))\n",
        "        else:\n",
        "            # Only a single letter in contour\n",
        "            char_regions.append((x, y, w, h))\n",
        "\n",
        "    # Ignore image if less or more than 4 regions detected\n",
        "    if len(char_regions)!=4:\n",
        "        return None\n",
        "    # Sort regions by their X coordinates\n",
        "    char_regions.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Character images\n",
        "    char_images = []\n",
        "    # Save each character as a single image\n",
        "    for x, y, w, h in char_regions:\n",
        "        # Extract character from image with 2px margin\n",
        "        char_image = gray_image[y - 2:y + h + 2, x - 2:x + w + 2]\n",
        "        # Save character images\n",
        "        char_images.append(char_image)\n",
        "\n",
        "    # Return character images\n",
        "    return char_images\n",
        "\n",
        "def make_feature(char_image, width=20, height=20):\n",
        "    resized = resize_to_fit(char_image, width, height)\n",
        "    resized = resized.astype(\"float32\") / 255.0\n",
        "    resized = np.expand_dims(resized, axis=-1)\n",
        "    return resized"
      ],
      "metadata": {
        "id": "MgczY4m0r-qV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. individual character dataset from CAPTCHAs\n",
        "image_paths = sorted(glob.glob(\"./captcha-images/*.png\"))\n",
        "print(\"Found images:\", len(image_paths))\n",
        "\n",
        "X_chars = []\n",
        "y_chars = []\n",
        "captcha_images = []\n",
        "captcha_texts = []\n",
        "\n",
        "for path in image_paths:\n",
        "    gray = load_transform_image(path)\n",
        "    text = extract_captcha_text(path)\n",
        "\n",
        "    # keep original CAPTCHA image for later visualization/eval\n",
        "    captcha_images.append(gray)\n",
        "    captcha_texts.append(text)\n",
        "\n",
        "    # segment characters\n",
        "    chars = extract_chars(gray)\n",
        "    if chars is None or len(chars) != 4:\n",
        "        continue\n",
        "\n",
        "    # build per-character samples\n",
        "    for char_img, char_label in zip(chars, text):\n",
        "        X_chars.append(make_feature(char_img))\n",
        "        y_chars.append(char_label)\n",
        "\n",
        "X_chars = np.array(X_chars)\n",
        "y_chars = np.array(y_chars)\n",
        "print(\"Character samples:\", X_chars.shape, y_chars.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9ija9jrsEel",
        "outputId": "d9d28792-79d9-4dec-e5d6-72e010adbb7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found images: 1136\n",
            "Character samples: (4468, 20, 20, 1) (4468,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. train/test split, label encoding, transpose\n",
        "X_train_np, X_test_np, y_train_text, y_test_text = train_test_split(\n",
        "    X_chars, y_chars, test_size=0.2, random_state=42, stratify=y_chars\n",
        ")\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train_text)\n",
        "y_test  = le.transform(y_test_text)\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "print(\"num_classes:\", num_classes)\n",
        "\n",
        "# NHWC -> NCHW\n",
        "X_train = np.transpose(X_train_np, (0, 3, 1, 2)).astype(np.float32)\n",
        "X_test  = np.transpose(X_test_np,  (0, 3, 1, 2)).astype(np.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T25V5MTptoXm",
        "outputId": "202b0758-7d1f-4b09-f425-b1769bf64301"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. dataset + dataloader\n",
        "class CaptchaCharDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(CaptchaCharDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(CaptchaCharDataset(X_test,  y_test),  batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "NJ5uNyKkt34K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. pytorch cnn\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "IPmf71kvuX1i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. train + eval loops\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def run_epoch(model, loader, train=True):\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, total_correct, total = 0.0, 0, 0\n",
        "\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        logits = model(Xb)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == yb).sum().item()\n",
        "        total += Xb.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "epochs = 10\n",
        "for e in range(1, epochs + 1):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n",
        "    te_loss, te_acc = run_epoch(model, test_loader,  train=False)\n",
        "    print(f\"Epoch {e:02d} | train {tr_loss:.4f} acc {tr_acc:.4f} | test {te_loss:.4f} acc {te_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U1v5FI0urxk",
        "outputId": "f9a33365-15a4-4628-a6fd-566fa4a86395"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train 3.3517 acc 0.0853 | test 3.0606 acc 0.1544\n",
            "Epoch 02 | train 2.0390 acc 0.4597 | test 0.9971 acc 0.7047\n",
            "Epoch 03 | train 0.6520 acc 0.8391 | test 0.4496 acc 0.9027\n",
            "Epoch 04 | train 0.3218 acc 0.9379 | test 0.2663 acc 0.9463\n",
            "Epoch 05 | train 0.2002 acc 0.9670 | test 0.1741 acc 0.9709\n",
            "Epoch 06 | train 0.1438 acc 0.9751 | test 0.1465 acc 0.9743\n",
            "Epoch 07 | train 0.1062 acc 0.9824 | test 0.1133 acc 0.9799\n",
            "Epoch 08 | train 0.0783 acc 0.9874 | test 0.0988 acc 0.9821\n",
            "Epoch 09 | train 0.0642 acc 0.9888 | test 0.0906 acc 0.9821\n",
            "Epoch 10 | train 0.0508 acc 0.9899 | test 0.0892 acc 0.9776\n"
          ]
        }
      ]
    }
  ]
}